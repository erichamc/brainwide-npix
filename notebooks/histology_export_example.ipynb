{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sessions = []\n",
    "# recordings are [mouse_name]_[date] and we assume one insertion per mouse per day\n",
    "recordings = [\"mousename1_date1\", \"mousename2_date2\"]\n",
    "# path to histology points or channel position map data by mouse name\n",
    "histology_directory = {\"mousename1\": \"/path/to/registered/histology/\",\n",
    "                       \"mousename2\": \"/path/to/registered/histology/\",\n",
    "                      }\n",
    "# in the processed data directory, we expect one recording folder per date matching the glob: *{curr_name}*{curr_date}*\n",
    "processed_data_directory = {\n",
    "    \"mousename1\": \"/path/to/catgt/kilosort/tprime/and/ecephys/processed/data/mousename1/\",\n",
    "    \"mousename2\": \"/path/to/catgt/kilosort/tprime/and/ecephys/processed/data/mousename2/\",\n",
    "}\n",
    "\n",
    "# replace path below with directory to contain results of probe placement into atlas\n",
    "output_directory = os.path.join('/directory/to/export/atlas/probe/locations/', 'hist_export_data')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "atlas_pixel_size = [10., 10., 10.]\n",
    "pixels_per_micron = 1./atlas_pixel_size[0]\n",
    "\n",
    "def compute_tract(pos):\n",
    "    \"\"\" Takes points pos as input and computes a tract bottom and vector\n",
    "    \"\"\"\n",
    "    z_idx = 1\n",
    "    r0 = pos[pos[:,z_idx] == pos[:,z_idx].max()]\n",
    "    top_of_tract = pos[pos[:,z_idx] == pos[:,z_idx].min()]\n",
    "    rel_pos = pos - r0\n",
    "    U,S,V = np.linalg.svd(rel_pos)\n",
    "    V = V[0,:]\n",
    "    tract_len = np.linalg.norm(top_of_tract - r0)\n",
    "    tmax = tract_len / np.linalg.norm(V)\n",
    "    if np.linalg.norm(top_of_tract-(tmax*V+r0)) > np.linalg.norm(top_of_tract-r0):\n",
    "        V = -V\n",
    "    tvals = np.arange(tmax)\n",
    "    tract = np.tile(tvals.T,[3,1]).T * V + r0\n",
    "    return tract, r0, V\n",
    "\n",
    "def transform_to_atlas(pos, r0, V, pixels_per_micron=pixels_per_micron):\n",
    "    \"\"\"\n",
    "    Return the brain areas for an array of points \n",
    "    Args:\n",
    "        pos: 2D array of neuron positions along the electrode in um \n",
    "    Returns:\n",
    "        transformed_pos: positions of each unit in reference space, in pixels\n",
    "    \"\"\"\n",
    "    if len(pos.shape) == 1:\n",
    "        pos_pix = pos * pixels_per_micron\n",
    "    else:\n",
    "        pos_pix = pos[:,1] * pixels_per_micron # if have 2d coords, just use depth\n",
    "    pos_pix = np.repeat(pos_pix,3).reshape([len(pos_pix),3]) # make Nx3 array to multiply by V\n",
    "    transformed_pos = r0 + pos_pix / np.linalg.norm(V) * V\n",
    "    return transformed_pos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load all experiments and transform all unit positions into atlas coords (and get area locations)\n",
    "\n",
    "for recording in recordings:\n",
    "    \n",
    "    curr_name = recording.split('_')[0]\n",
    "    curr_date = recording.split('_')[1]\n",
    "    \n",
    "    print(f'Processing: {recording}...')\n",
    "    \n",
    "    # grab file list for trajectories of a given insertion (by date)\n",
    "    # trajectory filename convention is: [imecN]_[date]_[tract_name].csv\n",
    "    tract_files = sorted(glob.glob(os.path.join(histology_directory[curr_name], f\"*{curr_date}*.csv\")))\n",
    "    tract_names = [os.path.basename(f).split('.csv')[0] for f in tract_files]\n",
    "        \n",
    "    transformed_chans = []\n",
    "    transformed_locs = []\n",
    "    chan_probe_id = []\n",
    "\n",
    "\n",
    "    for i, tract in enumerate(tract_names):\n",
    "        # get probe number\n",
    "        idx = int(tract.split('_')[0].split('imec')[-1])\n",
    "        \n",
    "        ecephys_output_dir = glob.glob(os.path.join(processed_data_directory[curr_name], f\"*{curr_name}*{curr_date}*\", f\"{curr_name}_{curr_date}*imec{idx}\", f\"imec{idx}_ks2\"))[0]\n",
    "        \n",
    "        ### Reconstruct trajectory from points -- BEGIN\n",
    "        # comment out below and skip to load _transformed_chans if already have it\n",
    "        \n",
    "        # get traced points\n",
    "        pts = np.array(pd.read_csv(tract_files[i])[[\"axis-0\",\"axis-1\",\"axis-2\"]].astype('float64'))\n",
    "        \n",
    "        # get trajectory\n",
    "        t, r0, V = compute_tract(pts)\n",
    "                \n",
    "        # get channel positions\n",
    "        chan_pos = np.load(os.path.join(ecephys_output_dir, \"channel_positions.npy\"))\n",
    "        \n",
    "        _chan_probe_id = np.array(chan_pos.shape[0]*[idx])\n",
    "        \n",
    "        # transform channel positions to atlas using trajectory\n",
    "        _transformed_chans = transform_to_atlas(chan_pos, r0, V)\n",
    "        \n",
    "        ### Reconstruct trajectory from points -- END\n",
    "        \n",
    "        # Uncomment to load existing channel-atlas locations\n",
    "        # _transformed_chans = np.load(\"/path/to/transformed/chan/positions.npy\")\n",
    "        \n",
    "        # transform clusters to atlas\n",
    "        if os.path.exists(os.path.join(ecephys_output_dir, \"cluster_info.tsv\")):\n",
    "            metrics = pd.read_csv(os.path.join(ecephys_output_dir, \"cluster_info.tsv\"), sep=\"\\t\")\n",
    "        else:\n",
    "            metrics = pd.read_csv(os.path.join(ecephys_output_dir, \"metrics.csv\"))\n",
    "        peak_cluster_channels = np.array(metrics[\"peak_channel\"])\n",
    "        _transformed_locs = _transformed_chans[peak_cluster_channels]\n",
    "\n",
    "        transformed_chans.append(_transformed_chans)\n",
    "        transformed_locs.append(_transformed_locs)\n",
    "        chan_probe_id.append(_chan_probe_id)\n",
    "\n",
    "    transformed_chans = np.vstack(transformed_chans)\n",
    "    transformed_locs = np.vstack(transformed_locs)\n",
    "    chan_probe_id = np.hstack(chan_probe_id)\n",
    "    \n",
    "    np.savez(os.path.join(output_directory, f\"{curr_name}_{recording}.npz\"),\n",
    "                        transformed_locs=transformed_locs, transformed_chans=transformed_chans, chan_probe_id=chan_probe_id)\n",
    "print('Done!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}